Running SLURM prolog script on pink54
===============================================================================
Job started on Sun Aug  5 11:08:14 BST 2018
Job ID          : 123979
Job name        : saliency-batch
WorkDir         : /mainfs/lyceum/grm1g17/lasagne4bio/test_saliency
Partition       : lyceum
Num hosts       : 1
Num cores       : 14
Num of tasks    : 14
Hosts allocated : pink54
Job Output Follows ...
===============================================================================
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11105' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '43261' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11106' (I am process '11107')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
INFO (theano.gof.compilelock): Waiting for existing lock by process '13902' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '13902' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '13902' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '13902' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '13902' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '14961' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '46473' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16459' (I am process '14259')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{156}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155]}, TensorConstant{156}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (156,), (), (156,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(156), 'not shown', array(156), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{156}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155]}, TensorConstant{156}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (156,), (), (156,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(156), 'not shown', array(156), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{156}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155]}, TensorConstant{156}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (156,), (), (156,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(156), 'not shown', array(156), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '19421' (I am process '19311')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{156}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155]}, TensorConstant{156}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (156,), (), (156,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(156), 'not shown', array(156), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
INFO (theano.gof.compilelock): Waiting for existing lock by process '19421' (I am process '19871')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '19421' (I am process '19871')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '19421' (I am process '19871')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '19421' (I am process '19871')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '19421' (I am process '19871')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '19421' (I am process '19871')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{156}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155]}, TensorConstant{156}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (156,), (), (156,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(156), 'not shown', array(156), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:02:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '50121' (I am process '20939')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{156}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155]}, TensorConstant{156}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (156,), (), (156,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(156), 'not shown', array(156), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
==============================================================================
Running epilogue script on pink54.

Submit time  : 2018-08-05T11:08:11
Start time   : 2018-08-05T11:08:13
End time     : 2018-08-05T12:01:09
Elapsed time : 00:52:56 (Timelimit=05:40:00)

Job ID: 123979
Array Job ID: 123977_42
Cluster: i5
User/Group: grm1g17/fp
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 14
CPU Utilized: 00:29:59
**** Please note that the CPU efficency of your job is less than 50% ****
**** Ask the HPC team for advice -- if you need it
**** CPU Efficiency: 4.05% of 12:21:04 core-walltime

Memory Utilized: 6.10 GB

