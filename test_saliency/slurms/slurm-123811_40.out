Running SLURM prolog script on pink60
===============================================================================
Job started on Sun Aug  5 07:45:24 BST 2018
Job ID          : 123811
Job name        : saliency-batch
WorkDir         : /mainfs/lyceum/grm1g17/lasagne4bio/test_saliency
Partition       : lyceum
Num hosts       : 1
Num cores       : 14
Num of tasks    : 14
Hosts allocated : pink60
Job Output Follows ...
===============================================================================
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{196}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195]}, TensorConstant{196}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (196,), (), (196,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(196), 'not shown', array(196), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{196}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195]}, TensorConstant{196}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (196,), (), (196,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(196), 'not shown', array(196), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
INFO (theano.gof.compilelock): Waiting for existing lock by process '13822' (I am process '26961')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '13822' (I am process '26961')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '13822' (I am process '26961')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{196}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195]}, TensorConstant{196}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (196,), (), (196,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(196), 'not shown', array(196), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '27722')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{196}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195]}, TensorConstant{196}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (196,), (), (196,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(196), 'not shown', array(196), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{196}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195]}, TensorConstant{196}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (196,), (), (196,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(196), 'not shown', array(196), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '16044' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '36651' (I am process '29433')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
ERROR (theano.gof.cmodule): [Errno 122] Disk quota exceeded: '/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/tmpxorgwswd/__init__.py'
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 208, in compute_tensor_jurtz
    get_gradients = theano.function(inputs=[sym_x], outputs=gradients)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function.py", line 317, in function
    output_keys=output_keys)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 1841, in orig_function
    fn = m.create(defaults)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 1715, in create
    input_storage=input_storage_lists, storage_map=storage_map)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 699, in make_thunk
    storage_map=storage_map)[:3]
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/vm.py", line 1091, in make_all
    impl=impl))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 866, in make_thunk
    on_unused_input='ignore')
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function.py", line 317, in function
    output_keys=output_keys)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 1841, in orig_function
    fn = m.create(defaults)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 1715, in create
    input_storage=input_storage_lists, storage_map=storage_map)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 699, in make_thunk
    storage_map=storage_map)[:3]
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/vm.py", line 1091, in make_all
    impl=impl))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/cmodule.py", line 1181, in module_from_key
    module = lnk.compile_cmodule(location)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/cc.py", line 1523, in compile_cmodule
    preargs=preargs)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/cmodule.py", line 2398, in compile_str
    open(os.path.join(location, "__init__.py"), 'w').close()
OSError: [Errno 122] Disk quota exceeded: '/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/tmpxorgwswd/__init__.py'
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{196}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195]}, TensorConstant{196}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (196,), (), (196,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(196), 'not shown', array(196), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Using cuDNN version 7005 on context None
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:83:00.0)
/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using Theano backend.
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '42898' (I am process '31033')
INFO (theano.gof.compilelock): To manually release the lock, delete /mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/lock_dir
Train path is downloaded ...
Loading train data ...
Loading splits ...
Using configurations: 'pureConv'
Build model
Build eval function
Load parameters
Compute saliencies
0
1
Traceback (most recent call last):
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "saliency.py", line 295, in <module>
    main_saliencies_jurtz()
  File "saliency.py", line 242, in main_saliencies_jurtz
    compute_tensor_jurtz(X[idx], mask[idx], args)
  File "saliency.py", line 210, in compute_tensor_jurtz
    grads = get_gradients(X)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 917, in __call__
    storage_map=getattr(self.fn, 'storage_map', None))
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gof/link.py", line 325, in raise_with_op
    reraise(exc_type, exc_value, exc_trace)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/compile/function_module.py", line 903, in __call__
    self.fn() if output_subset is None else\
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 963, in rval
    r = p(n, [x[0] for x in i], o)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/scan_module/scan_op.py", line 952, in p
    self, node)
  File "theano/scan_module/scan_perform.pyx", line 522, in theano.scan_module.scan_perform.perform (/mainfs/lyceum/grm1g17/.theano/compiledir_Linux-3.10-el7.x86_64-x86_64-with-redhat-7.4-Maipo-x86_64-3.5.5-64/scan_perform/mod.cpp:6179)
  File "/lyceum/grm1g17/.conda/envs/localenv/lib/python3.5/site-packages/theano/gpuarray/type.py", line 375, in value_zeros
    context=self.context)
  File "pygpu/gpuarray.pyx", line 682, in pygpu.gpuarray.zeros
  File "pygpu/gpuarray.pyx", line 762, in pygpu.gpuarray.empty
  File "pygpu/gpuarray.pyx", line 700, in pygpu.gpuarray.pygpu_empty
  File "pygpu/gpuarray.pyx", line 301, in pygpu.gpuarray.array_empty
pygpu.gpuarray.GpuArrayException: b'cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory'
Apply node that caused the error: for{gpu,scan_fn}(TensorConstant{196}, GpuArrayConstant{[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195]}, TensorConstant{196}, GpuSubtensor{int64, :int64:, int64}.0, GpuFromHost<None>.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, InplaceGpuDimShuffle{x,0,x}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{0,1,x,2}.0, GpuFromHost<None>.0, GpuFromHost<None>.0, InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{sqrt((i0 + i1))}}[]<gpuarray>.0, InplaceGpuDimShuffle{x,0}.0, GpuElemwise{sgn}[]<gpuarray>.0, InplaceGpuDimShuffle{1,0}.0, GpuSoftmaxWithBias.0, GpuFromHost<None>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, Rebroadcast{?,?,0}.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0, GpuElemwise{Sgn}[(0, 0)]<gpuarray>.0)
Toposort index: 293
Inputs types: [TensorType(int64, scalar), GpuArrayType<None>(int64, vector), TensorType(int64, scalar), GpuArrayType<None>(float32, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (True, False, True)), GpuArrayType<None>(float32, (False, False, True, False)), GpuArrayType<None>(int64, vector), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, row), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix), GpuArrayType<None>(int64, vector), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 4D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D), GpuArrayType<None>(float32, 3D)]
Inputs shapes: [(), (196,), (), (196,), (2,), (1, 16, 1), (1, 16, 1), (16, 42, 1, 7), (64, 16, 700), (1, 16, 1), (1, 16, 1), (16, 42, 1, 5), (1, 16, 1), (1, 16, 1), (16, 42, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 90, 1, 7), (1, 16, 1), (1, 16, 1), (16, 90, 1, 5), (1, 16, 1), (1, 16, 1), (16, 90, 1, 3), (2,), (1, 16, 1), (1, 16, 1), (16, 138, 1, 7), (1, 16, 1), (1, 16, 1), (16, 138, 1, 5), (1, 16, 1), (1, 16, 1), (16, 138, 1, 3), (2,), (3,), (200, 186), (1, 200), (1, 200), (44800, 200), (8, 200), (44800, 8), (2,), (64, 16, 700), (64, 16, 1, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700), (64, 16, 700)]
Inputs strides: [(), (8,), (), (32,), (8,), (64, 4, 4), (64, 4, 4), (1176, 28, 28, 4), (44800, 2800, 4), (64, 4, 4), (64, 4, 4), (840, 20, 20, 4), (64, 4, 4), (64, 4, 4), (504, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (2520, 28, 28, 4), (64, 4, 4), (64, 4, 4), (1800, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1080, 12, 12, 4), (8,), (64, 4, 4), (64, 4, 4), (3864, 28, 28, 4), (64, 4, 4), (64, 4, 4), (2760, 20, 20, 4), (64, 4, 4), (64, 4, 4), (1656, 12, 12, 4), (8,), (8,), (4, 800), (800, 4), (800, 4), (800, 4), (4, 32), (32, 4), (8,), (44800, 2800, 4), (44800, 2800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4), (44800, 2800, 4)]
Inputs values: [array(196), 'not shown', array(196), 'not shown', gpuarray.array([  1, 700]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([42, 48]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([48, 90]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([ 48, 138]), gpuarray.array([ 64, 700, 186]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', gpuarray.array([44800,     8]), 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown', 'not shown']
Outputs clients: [[HostFromGpu(gpuarray)(for{gpu,scan_fn}.0)]]

HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.
HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.
