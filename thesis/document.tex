\documentclass{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{appendix} 
\newcommand{\uvec}[1]{\boldsymbol{\hat{\textbf{#1}}}}

\title{Tell Me Which Party To Vote For: A New Proposal For Voting Advice Applications}
\author{javierpmt }
\date{August 2018}

\begin{document}

\maketitle

\begin{abstract}
    Voting Advice Applications (VAAs) have proliferated in the last years in many European countries, and their effects have been extensively discussed. One of their main goals is to increase voter's political competence by notifying users of their closest political party according to ``their own preferences". In order to do this, VAAs compare and aggregate users' and political parties' preferences on a set of policy issues. In this paper, I argue that current VAAs are not adequate to increase voter's political competence even using the narrow conception of political competence that the application assumes, and propose a different method based on machine learning techniques. First, I define four normative criteria to evaluate VAAs: informativeness, respect for users' way of comparing and aggregating policy issues, realism and transparency. Second, I argue that current VAAs compare and aggregate users and parties' policy preferences following an empirically bleak method. Although the model is theoretically informative, the recommendation is not based on a realistic combination of the users' most important policy preferences and neither does it consider whether the user is an issue-voter taking mainly into account the policy positions of the parties in order to cast their vote. Third, I propose a ``Learning VAA" which combines some features of current VAAs with machine learning techniques. This model learns to compare and weight policy issues relying on the political party that the users would choose if they based their voting decision solely on the basis of parties' policy positions. Lastly, I test my model and argue that it is informative, respectful of users' way of comparing and aggregating policy issues and realistic. However, I note that the main limitation of my model is lack of transparency. 
\textbf{}\end{abstract}


\newpage
\tableofcontents
\newpage

\section{Introduction}

The aim of this paper is to critically evaluate the current models of Voting Advice Applications (VAAs) and propose a different VAA based on a learning algorithm. The discussion on the methodology behind VAAs and its normative implications is important because these applications have proliferated in recent years \cite{marschall2014voting}. VAAs have become a part of the electoral process in many countries, reaching a considerable part of the electorate in most European  elections, and their roles have diversified \cite{alvarez2014party}. According to the main line of literature, one of their main goals is to increase users' political competence by allowing them to acknowledge the disagreement between their own political preferences and ``the policy standpoints of political parties" \cite[233]{Garzia2014}. My starting point is that VAAs are considered to play a role on the electoral process in many countries, and therefore it is important to evaluate the empirical validity and the normative implications of their methodology \cite{fossen2014s}.  
\\ 

VAAs have been subject of research in different fields \cite{alvarez2014party}. On the one hand, there is a branch of literature focusing on the different effects of these applications \cite{marschall2012voting}. While the majority of research shows that VAAs have an effect on increasing turnout and political knowledge at the aggregate level \cite{garzia2017voting}, those experiments discounting users' self-selection bias found scarce impact on increasing turnout at the individual level \cite{maheo2017information}. Another branch of literature studies the socio-demographic characteristics of VAA users. The usual conclusion is that the average user “is young, highly educated and keenly interested in politics” \cite[253]{cedroni2010voting}. My essay addresses a nascent area in VAA literature that mixes a methodological and a normative approach. Regarding the former, there has been discussion on the methods used by VAAs to provide recommendations \cite{Mendez2017}, the importance of the statement selection \cite{walgrave2009voting} and the treatment of the data \cite{Djouvas2016}. With respect to the normative implications of the current methods of VAAs', the few philosophical papers on VAAs have typically focused on the influence of the application on a citizen's conception of democracy, but not on the different methods to provide a recommendation   \cite{anderson2014matching}. Only in exceptional cases have some authors pointed out from a normative perspective the importance of VAAs' methods in increasing voter's political competence \cite{fossen2014s}. 
\\

My research has an ambitious long-term practical goal: to replace current VAA methods of recommendation. In the short term, a version of my method should be tested on new VAAs, as will be proposed at the ECPR General Conference in Hamburg 2018. As I use data from the EU-Vox 2014, a VAA launched in 2014 for the European Parliamentary Election, ideally the model should be tested for the EU-Vox 2019. Hopefully, as part of the team leading the EU-Vox 2019 in Spain, I will have the opportunity to test the proposed methodology. In any case, the data will not be available until 2019, so at the moment I am unable to fully test the method. Fortunately, some contributions can still be shown with existing data. 
\\

In the following, I first present the problem of voters' lack of political competence and how VAAs pretend to alleviate this by assuming a narrow conception of democracy inspired by social choice theory. Second, I analyse four criteria for evaluating VAAs' methods of recommendation: informativeness, respect for the users' way of comparing and aggregating policy issues, realism and transparency. Third, I explain analytically the current VAA methods of recommendation. I argue that it has structural failures in relation to the established criteria, undermining their goal of increasing political competence. Lastly, I explain and empirically test my proposed VAA methodology based on machine learning techniques. I argue that my proposal is superior regarding its informativeness, respect for users' way of aggregating and comparing policy issues, and realism, and note that it has problems of transparency.    


\section{VAAs and the problem of citizen (in)competence} 

\subsection{Democracy and voters' political competence}

The question of the importance of voter's political competence for the correct functioning of democracy has been subject to unresolved controversies. As Dahl puts it, the very standpoint is the notion that ``if democracy is to work, it would seem to require a certain level of political competence on the part of its citizens" \cite{dahl1992problem}. Concerns about voters' lack of political competence were present in the views of some striking philosophers such as Plato, Cicero and Schumpeter and were explanatory of their concerns about democracy \cite{caplan2011myth}. For example, Mill, worried about possible undesirable consequences due to the extension of universal suffrage, argued that giving additional weight to politically competent voters would improve collective political intelligence and the outcomes of
democratic elections \cite{stuart1859liberty}. He considered politically competent voters to be the well-educated or vocationally well-positioned citizens, and believed that giving additional voting to them would be positive for everyone as they would have more opportunities to take better political decisions \cite{stuart1859liberty}. Partially following Mill's insights, I define a competent voter as someone with adequate capability and knowledge on policy issues to cast a vote which could advance her own policy
preferences \cite{carpini1996americans}. 
\\

This definition leads to the following question: What does ``adequate" knowledge on policy issues mean? In this paper, I do not evaluate the adequacy of voter' knowledge as a function of any appreciation of the ``goodness" of preferences nor on the rationality of the arguments displayed by the voter in defending her choice. Instead, VAAs take voters' preferences on policy issues for granted \cite{anderson2014matching}. They map the policy preferences of users and political parties on a set of issues, and recommend the party which best fits with the users' policy preferences according to criteria of comparison and aggregation of policy issues \cite{Mendez2012}. Therefore, VAAs implicitly define having political competence as having 1) adequate knowledge about the levels of agreement between voters' preferences on policy issues and the positions of political parties, and 2) the ability to compare and aggregate these policy issues into a single agreement coefficient which determines the  party to vote for \cite{Mendez2017}. 
\\ 

In order to have knowledge regarding the level of agreement between her preferences on any policy issue and the positions of the political party within it, a voter must know the existence of this policy issue and the position of political parties. It is expected that these knowledge conditions will be satisfied by VAAs: the very same questionnaire gives an approximate idea of the prominent policy issues at stake, and after receiving a recommendation for a party users can normally see the position of political parties in any policy issue and compare them with their own positions \cite{Garzia2014}. There are more complexities involved into the aggregation of these policy issues, which leads to VAAs' main outcome: the agreement coefficient which determines the recommended party \cite{louwerse2014design}. This agreement coefficient refers to one of the conditions stated as fundamental for voter's political competence in VAAs: the aggregation of the levels of agreement with the political parties in the set of policy issues in order to recommend a party for the user to vote for \cite{Mendez2017}. The agreement coefficient aims to increase voters' political competence by simplifying, in a meaningful way, the complex process of comparing and aggregating policy preferences \cite{marschall2010impact}. From this perspective, VAAs aim to be like ``a computerized expert system" which ``assist an architectural engineer in navigating complex decisions about the construction of a building" \cite[246]{fossen2014s}. 
\\

The first question to determine is what conception of democracy is presupposed by VAAs with this understanding of voter's  political competence. The approach of VAAs fits closely with the normative conception of democracy defended by social choice theory, in which the democratic process can be understood as a means of aggregating preferences on policy issues in order to come up with a political party that respects and considers these policy preferences fairly  \cite{anderson2014matching}. According to this view, a competent voter ``is well informed about the options on the electoral menu, and therefore competent to choose a political party that matches his or her preferences" \cite[247]{fossen2014s}. However, the notion assumed by VAAs on democracy and political competence is disputed. Different conceptions of democracy and citizenship cast the problem of citizen competence in a different light than social choice theory \cite{fossen2014s}. For example, advocates of deliberative democracy are more worried about how voters form their policy preferences than about their lack of knowledge about the disagreement between their policy positions and the positions of political parties \cite{caplan2011myth}. This discussion is a deeper one which goes beyond the objective of this paper; VAAs are unable to inform citizens regarding the genuine goodness of a specific position on any issue, and any design of the application assumes that citizens have legitimate policy preferences on a set of policy issues which should be compared with those of the political parties in order to decide which party to vote for \cite{anderson2014matching}. VAAs are only concerned with matching citizens and political parties using a similarity criteria: the closer the party and the citizen on the policy issues, the greater the chance of being the adequate voting party for the citizen \cite{Mendez2012}. Therefore, VAAs treat given policy-preferences on a set of issues as a good way to choose one's voting party \cite{fossen2014s}. In the following, I assume the arguable and narrow conception of political competency that every VAA so far has assumed \cite{anderson2014matching}. The goal of this paper is not to challenge it. Instead, I argue that the methods of current VAAs are insufficient to advance even this narrow conception of political competence. 

\subsection{Advancing VAAs' vision of voters' political competence}

According to the main line of literature, low levels of political knowledge are widely exhibited by most citizens  \cite{carpini1996americans}. For example, Ferejohn et al. stated that ``nothing is certain (to) the student of public opinion and democracy more forcefully than the paucity of information most people possess about politics" \cite[3]{ferejohn1990information}. Certainly, it has been empirically shown that voters lack knowledge about policy issues, suffer predictable biases due to their lack of information regarding how they place political parties in these issues, and experience cognitive dissonance when explaining their reasons for voting \cite{caplan2011myth}. Moreover, citizens' lack of knowledge about the policy issues at stake and the position of the political parties within them is not normally an impediment to going to the polls \cite{hardin2006ignorant}. For that reason, few researchers deny that there is ``room for improvement" \cite [245]{fossen2014s} regarding the notion of voter's political competence advanced by VAAs. If this is true, there is a gap between what might be desirable in order to meet the standards for being a competent voter according to VAAs and the current level of voters' political competence  \cite{fossen2015electoral}. This political competence gap has been seen as a unavoidable reality to which political systems can respond in different ways, like enforcing politically independent authorities or increasing the role of experts \cite{caplan2011myth}. Another typical alternative is increasing voter's political competence in order to bridge the gap between what they should know to vote competently and what they actually know \cite{dahl1992problem}. VAAs are supposed to tackle this problem by offering the users knowledge on the policy issues at stake, the positions of the parties within it and an agreement score based on a comparison and aggregation of the preferences of the user and the positions of the political parties \cite{fossen2014s}.
\\

From my perspective, if VAAs can make citizens more competent, even in the narrow sense of political competence that VAAs advance, they can play a positive role for individuals and society.  Voters' lack of political competence poses a problem because politicians are responsible for a large part of the budget of a country, and they take fundamental decisions regarding the lives of their governed on many policy issues \cite{somin1998voter}. Therefore, it seems problematic to cast a vote based on mistaken beliefs about the policy issues or the political positions of the parties because this would mean that ballots may have no relationship with what  voters care about \cite{Garzia2014}. Brennan (2011) has argued that those people who vote without knowing the policy issues or the positions of the political parties in them are engaging in a form of recklessness, as they act without knowing whether their voting behaviour cause harm to others. Carpini and Keeter (1996) consider being a politically competent voter to be comparable with having access to “the currency of citizenship”. From their standpoint, a politically competent voter acquires a significant resource ``for meeting the role of the politically active and involved citizen" \cite [8]{carpini1996americans}. VAAs are supposed to increase this notion of political competence in a straightforward and transparent way which respects users' preferences
\cite{marschall2014voting}. They are expected to perform an important function for voters, especially for those considering multiple parties and not knowing exactly what the total disagreement between their policy preferences and the positions of these political parties is \cite{garzia2017voting}.

\section{Evaluating VAAs}

In VAAs, developers must unavoidably take some decisions which affect the process of recommendation \cite{fossen2015electoral}. First, they decide the set of policy issues considered by the application. Second, they place the political parties within them. Third, they elaborate a distance matrix for weighting levels of agreement between users and parties' preferences on the issues. Lastly, they decide the weight of each policy issue. Therefore, even the best developed VAA will not simply reflect ``what is at stake in the election by neutrally passing along information" \cite [341]{fossen2015electoral}. Rather, political information is structured by developers’ decisions, which shall be evaluated in order to know whether the VAA is likely to increase political competence. There are at least four criteria which can help in making this evaluation: informativeness, respect for users' way of comparing and aggregating policy issues, realism and transparency. 

\subsection{Informativeness}

To increase voter's political competence, VAAs must be informative about those things increasing their notion of voter's political competence. I argued previously that for a VAA a competent voter should 1) compare their policy preferences with the positions of the political parties on a set of prominent policy issues and 2) aggregate the disagreement with the political parties on the set of policy issues in a meaningful way to decide which party to vote for \cite{Mendez2017}. Therefore, in order to be informative, a VAA must provide information on the policy issues at stake, the position of the parties on these issues and a single outcome in the form of a recommended party which is the result of an aggregation of the distances between the parties and the users on these issues \cite{fossen2014s}. If VAAs provide that information to the user, this will facilitate the process of comparing and aggregating their levels of agreement with the parties on the policy issues. 


\subsection{Respect for users' way of comparing and aggregating policy preferences} 

Ideal VAAs are supposed to offer users ``an unobstructed view of the political landscape, and their place within it" \cite[291]{dinas2014look}. In this sense, unobstructed means that the recommendation depends on users' own preferences on policy issues. This idea can be considered differently. For example, making the whole process of recommendation without changing where the user has placed herself is uncontroverted as every VAA actually completes this operation because it takes policy preferences as given \cite{anderson2014matching}. However, this understanding of respect for the users' own preferences does not fully inform the way in which users truly form their voting decisions by comparing and aggregating their policy preferences. For example, a VAA might not recommend the closest political party according to users' own preferences if it does not give enough weight to a  decisive policy issue according to users. In that case, instead of adjusting to users' own preferences in order to recommend a party, VAAs would evaluate how users should compare and aggregate their level of agreement with political parties. This is not what VAAs are supposed to do. If there is a systematic bias on VAAs' way of comparing and aggregating policy preferences, the goal of increasing voters' political competence will be critically undermined, as the recommendation will complicate instead of facilitating the already complex process of voting competently. In that case, users would have very good reasons for not considering the recommendation. \\

Unfortunately, it is impossible to expect a VAA to offer a fully unobstructed view of users' disagreement with political parties as the unavoidable decisions will affect the way in which the application represents the user and provides a recommendation \cite{fossen2015electoral}. However, there can be levels of respect for users' way of comparing and aggregating policy preferences relying on the method used. For example, a VAA can entirely depend on developers' own judgment or can consider how users aggregate and compare policy issues. There are at least two ways to take users into account. First, they can give users the opportunity to weight the questions relying on their importance in choosing the voting party (i.e. set up a button in order to declare that a question is of special relevance). It is not feasible to allow users to entirely decide the weighting of the questions, as it would demand an impressive amount of time and knowledge on policy issues. Therefore, offering the option of weighting the questions will not entirely solve the problem of aggregating policy preference by respecting users' way of doing it. Second, the weights of the question can be adapted to users following empirical methods and research. This can be mainly done in two different ways. First, using previous empirical data analysis that focuses on the importance of the policy issues (e.g. voter surveys). Second, using an algorithm that continuously learns to compare and aggregate policy issues to better emulate users' way of doing it. 

\subsection{Realism}
To increase political competency, VAAs must try to reflect the political reality of the world and be able to offer a (simplified) picture of the real world \cite{dinas2014look}. If VAAs do not capture a realistic disagreement between users and political parties, they are unable to offer a recommendation worth consideration. This recommendation would be incapable of increasing a voter's political competency on the real world, and thus it could not be applied into any practical decision; it would only be valid for the imaginary-world of VAA developers. As a result of the importance of realism, it has often been claimed that VAAs must be a mirror of the political landscape in which the user can get a complete look of her place within it \cite{dinas2014look}. This claim is an oversimplification of VAAs which can lead to misunderstandings because the application has a very narrow conception of democracy and voting informed by social choice theory, spatial politics and issue-voting, which cannot claim to be an entirely realistic version of politics \cite{fossen2015electoral}. Because many important voting factors are not considered by the application, VAAs will always fail to be entirely pure representations of political reality. For that reason, some authors have argued that, instead of mirrors of electoral reality, VAAs should be understood as dioramas \cite{fossen2015electoral}. From my point of view, understanding VAAs as dioramas depicts more accurately the scope of VAAs; this application cannot aspire to capture all the complex aspects of reality and must necessarily depict a not entirely realistic political landscape which is based on issue voting. Having said that, if VAAs aim to increase political competence they must aspire to be as realistic as possible and cannot offer a political landscape to the users that does not correspond with reality.
\\

The criterion of realism has a relationship with the previous one: a VAA considering users' way of comparing and aggregating preferences with a biased method will hardly be realistic. The main difference is that this criterion takes into consideration the political landscape that VAAs try to emulate. It accounts for whether VAAs offer a realistic matching to issue-voter users, and it does not misrepresent any political party. Therefore, according to this criterion, a VAA will fail if it is mostly recommending a set of political parties which have no relationship with users' expectations, and also if it over or under represents substantively some political parties without a sound justification. There are at least four ways to empirically measure this condition of realism. First, accuracy measures the percentage of predictions in accordance with users' expectations: the VAA recommends the same party that the users expected to vote for before filling in the application \cite{tsapatsoulis2015design}. Second, the mean rank evaluates how high the VAA placed the  preferred political party of the users \cite{tsapatsoulis2015design}. It offers complementary information to the accuracy measure, as it gives an idea of the position in which the previously preferred party is placed in the ranking of recommended political parties according to the agreement coefficient. Third, the confusion matrix assesses whether some political parties are over or under represented by the VAA. A confusion matrix is a specific table layout that allows visualization of whether the recommended political parties  correspond to those expected by users. Four, \textit{f-score} summarizes two key performance measures regarding each party: \textit{precision} (how many of the recommendations of that party were given to the right people) and \textit{recall} (how many of the members of that party were given it as a recommendation). All the parties f-scores can be combined into a single score by averaging through them. From my standpoint, a VAA will hardly be realistic if it suffers a consistent bias against or for a particular party. Therefore, if a VAA is consistently ignoring an important political party without a sound reason (e.g. the policy positions of the parties are really different from those that the users believe in), odds are that the VAA is not meeting the realism criterion.   
\\

The realism criterion faces two main objections. First, judging the VAA by how it meets an unfiltered set of users' expectations about preferred voting parties may be wrong as the voting parties are determined by many factors that VAAs are not meant to help a voter consider. Certainly, in the real world, issue voters cannot be assumed entirely. Many voters use different strategies to vote for a party beyond their position on policy issues; it has been empirically shown that voters use party identification, charismatic leadership or social cues to decide which party to vote for \cite{Mendez2012}. If there are voters who are not worried about their agreement with political parties on policy issues, VAAs cannot be expected to fulfil the expectations of these users by recommending a party which is in line with their policy preferences \cite{anderson2014matching}. Therefore, in these cases it is problematic to negatively evaluate the fact that the VAA does not recommend the users' expected party, as this situation may be due to factors beyond the control of the application. There are at least two ways to improve this situation. First, we can filter those users considering themselves ``issue-voters" (i.e. those declaring that they cast their vote ``solely on policy positions of parties") and evaluate the realism of the VAA according only to these users. The problem with this approach is that citizens may have intertwined reasons for voting for a party, and even if they consider themselves ``issue-voters" there will probably be many factors that are not considered by VAAs. Another alternative would be to ask users to reply to the following question: ``which party would you vote for insofar as your project is to base your vote solely on parties' policy positions?". In that case, it can be evaluated whether the VAA is giving the users the parties which they would have chosen in the case of being entirely issue voters. \\

The second objection is that this criterion can undermine the informativeness of VAAs, as it can limit the amount of learning a VAA can provide to users. Certainly, a VAA always offering the same party that users expect would be useless in increasing political competence, as it would not give any valuable information to cast a competent vote. This VAA would not be informative on the disagreement between users and political parties as it would merely adjust to users' wishes. This is not what this criterion aspires to. Instead, the realism criterion informs on VAAs' capability to draw a realistic political landscape based on a single premise: users’ political knowledge is imperfect but not total. Studies on VAA users have shown that they tend to be more interested in politics and have more knowledge about policy issues than the average citizen \cite{cedroni2010voting}. Assuming these knowledge conditions and ``issue-voters", the realism criterion informs that a VAA will hardly be realistic if it mostly recommends marginal parties to a representative sample of users not previously interested in these parties. There are three considerations to be made regarding the previous statement. First, the realism criteria must be balanced with the other criteria in order to evaluate VAAs (especially informativeness). Therefore, a VAA designer could decide to lose a little bit of realism in order to increase the informativeness of the application, or vice versa. Second, the realism criterion not only considers whether VAAs recommend the expected party to the user (accuracy), but also the position of the expected party in the set of possible recommended parties (mean rank) and whether each political party is over or under represented (confusion matrix). Therefore, it is a more comprehensive measure than a single comparison between users' expected and recommended party. Third, a realist VAA need not have a great percentage of accuracy, F-score or mean rank, and the role of the criterion is to preclude those VAAs having a percentage close to random matching or leading to a misrepresentation of particular parties without sound justifications. From this perspective, the realism criterion is better to exclude than to recommend any VAA method.
\\

Another complementary way to evaluate this criteria is to consider the percentage of users who declare that the application gave them realistic advice. I understand that most users can evaluate whether the recommendation is realistic. Certainly, this is not the case for every user as some of them might be obfuscated by receiving a totally unexpected recommendation because of their lack of knowledge about
the agreement between their policy preferences and the parties' position. However, this
should not happen in most cases as the imperfect knowledge that VAAs try to improve
is not a total ignorance of the political arena, and in this case most users are able to judge on whether the VAA can represent them accurately to provide a valuable recommendation. Of course, this is only plausible if users are issue-voters or are deliberating as if they were issue-voters, as otherwise there would be many non-considered factors which would undermine users' judgment of the VAA contribution. As before, there are two ways to solve this problem. First, we can differentiate between issue and non-issue voters and evaluate the opinions only of issue-voters. Second, VAAs can ask users the following question: do you believe you received valuable information from the VAA insofar as your project was to base your vote solely on policy positions of parties?".  


\subsection{Transparency} 

Lastly, it is important that VAAs are transparent in the sense of 1) allowing users and researchers open access to their methods, and 2) being understandable to users and researchers. First, this criterion means that the decisions taken by VAA developers should be accessible to both users and researchers \cite{gemenis2013estimating}. This is important in order to help the users understand why they have been recommended a particular party. Moreover, it can serve to advance the accountability of VAA developers, who might have hidden interests or just rely on non-accurate methods. Not being transparent may prevent any replication and improvement of the methods. The second aspect of the criterion of transparency is that the method should be understandable. For example, there may be problem of understanding any VAA method similar to black boxes, devices which can be seen in terms of their inputs and outputs without any knowledge of their internal workings. Very sophisticated methods for recommending a party may suffer that problem by making it impossible to really understand why a recommendation is given. For a user, this situation may undermine the goal of increasing her political competence by providing a meaningful aggregation of her disagreement with the political parties \cite{louwerse2014design}. For researchers, an opaque method may hinder its improvement, and this may lead to accountability problems. 



\section{Status Quo: Current VAAs}
 
\subsection{Explaining developers' decisions}

In current VAAs, most important decisions (i.e. establishing the policy issues and positions of the parties, weighting policy issues and creating the distance function for measuring disagreement) are taken ex ante by the developers \cite{louwerse2014design}. Parties' policy positions are generally agreed upon after a process of searching for information \cite{wagner2012matching}. For example, in the EU-Vox 2019 developers must first find in the party manifestos a statement indicating the position of the party. If there is no such a statement, they can go for official declarations by important party members, and if no information is found, they can either agree upon a policy issue position or leave the party as having ``no opinion" on the issue. Since then, policy issues and parties' positions are not modified by any further consideration even if they are proven wrong \cite{Mendez2017}. 
\\

All the questions are equally weighted in the aggregation, whose outcome is the agreement score determining the recommended party \cite{Mendez2012}. Therefore, current VAAs assume that users' way of aggregating policy issues is the simplest imaginable: all  policy issues are as important in deciding which party to vote for. To my knowledge, there has been no single empirical study on VAAs justifying the decision to weight all policy issues equally. At most, some VAAs give users the opportunity to declare that a question is unimportant or very important for them \cite{louwerse2014design}. The effect of pointing out that a question is of particular importance is also chosen ex-ante: weights are usually halved or doubled depending on the user's declaration \cite{wagner2012matching}. For example, if the user declares that a question regarding taxes is very important for her, the outcome from the distance function due to their degree of agreement with the political party on that question will be multiplied by two. 
\\

Regarding the comparison between users and parties' policy positions, VAA developers choose ex ante a matrix of distances between users and political parties, and use the same matrix throughout the questionnaire \cite{Mendez2012}. VAA developers have discussed whether to use proximity, directional or a hybrid distance function \cite{Mendez2017}. This discussion echoes one of the fundamental disagreements about theories on issue voting which confront proximity and directional logic \cite{merrill1999unified}. A proximity logic would mean that recommendations are based on voter-party distances, usually measured on a continuous scale \cite{downs1957economic}. In contrast, directional logic is indicated by three features. First, each policy issue has two different ‘sides’, for and against. Second, it is possible to express intensity of preference on each of the sides of the spectrum (i.e. ``agree" and ``completely agree"). Third, parties are not punished for holding more intense positions than voters \cite{rabinowitz1989directional}. Therefore, defenders of directional theory argue that voters mainly care about the fact that the political party is on their side of the ideological spectrum. For example, according to directional theory, a user declaring (``agree") regarding euthanasia would only care that the political party is in those positions advancing euthanasia (``agree" and ``completely agree"). In contrast, a proximity voter would give the same output to a party with the position ``completely agree" and ``neither agree or disagree", as they both are at a distance of one from ``agree". Currently,  distance matrices between users and parties' positions following either proximity or directional logic are created to weight the disagreement for each policy issue. Although some VAA developers do not publicise their distance matrix, most of them rely on a proximity logic \cite{Mendez2012}. 
\\

To evaluate whether VAAs are recommending a realistic set of parties, most VAA researchers have trusted in accuracy and mean rank between users' expected and recommended party \cite{tsapatsoulis2015design}. Some VAAs have tried to distinguish between issue-voters and non issue-voters based on self reporting \cite{Mendez2017}. To my knowledge, the question of the value of the recommendation given that the user is voting solely on the policy positions of the parties has never been asked. 


\subsection{Basic operation}

Current VAAs comprise a set of questions of size $N$. Answers to the questions are typically restricted to a Likert scale, expressing agreement in five degrees plus a \textit{No opinion} answer: $\mathcal{L} = \lbrace\: CA,\: A,\: N,\: D,\: CD,\: NO\:\rbrace$\footnote{Completely Agree, Agree, Neither Agree or Disagree, Disagree, Completely Disagree, No Opinion.}.
Each user gives an answer belonging to $\mathcal{L}$ for each question. A user \textit{profile}, $\Vec{u_i}$, is the vector containing the answers of user $i$ for all $N$ questions.
VAAs give recommendation among $K$ parties. Each party also has answers for every question, leading to $K$ analogous profiles, $\Vec{p_k}$.
The questions relate to the set of policy issues which should determine the chosen party (Figure \ref{fig:question}). 

\pagebreak

\begin{figure} [!h]
    \centering
    \centerline{\includegraphics[width=1\linewidth, bb = 0 0 850 615]{Question.pdf}}
    \caption{A question in the EU-Vox 2014 \cite{agathokleous2016applying}}
    \label{fig:question}
\end{figure}

The recommended party is the one with the highest agreement score, which is calculated by fixed algorithms computing each question independently: $f: \mathcal{L} \times \mathcal{L} \longrightarrow \mathbb{R}$. First, answers are transformed into a vector with 1 on the chosen answer and 0 on the others, so the inputs to the function are two binary vectors of size $|\mathcal{L}|$: $f':~\mathcal{B}^{|\mathcal{L}|} \times~\mathcal{B}^{|\mathcal{L}|} \longrightarrow~\mathbb{R}$. Second, each question is evaluated according to a \textit{distance matrix}~$D$ emulating the comparison process. In this process, the score for each question, $q_{ikj}$, will be determined by users and parties' encoded answers ($\Vec{u_{ij}}$ and $\Vec{p_{kj}}$) and the distance matrix ($D$):  

\begin{equation}
    q_{ikj} = f'( \Vec{u_{ij}}, \Vec{p_{kj}} ) = \Vec{u_{ij}} \times D \times \Vec{p_{kj}}^T \: .
    \label{eq:question_score}
\end{equation}

Third, the total agreement score, $s_{ik}$, is computed by squashing the scores for the $N$ questions according to some weights, $\Vec{w}$, that represent the importance of each question. Current VAAs weight all questions equally. 

\begin{equation}
    s_{ik} = \sum\limits_{j=1}^N w_j \: q_{ijk} = \Vec{w} \cdot \Vec{q_{ik}} \: .
    \label{eq:party_score}
\end{equation}

It is important to note that values from the distance matrix ($D$) are chosen ex-ante according to proximity,  directional or hybrid models. These matrixes (without the \textit{No Option} choice) used in most VAAs come from \cite{Mendez2012} and follow the proximity or directional logic explained above. The hybrid matrix is obtained from the average between the other two.  
\pagebreak

\begin{figure} [!h]
    \centering
    \centerline{\includegraphics[width=1\linewidth]{prox_dir_hyb.eps}}
    \caption{Distance matrix currently used in VAAs. Darker colours reflect lower scores which usually occur when parties and users disagree on the policy issue. The score of the questions ranges from -1 to 1 regarding user and party agreement on the policy issue. Closer scores to 1 will mean that the party and the user are more coincident on the policy issue and have more chances to be matched.}
    \label{fig:d_max}
\end{figure}

\subsection{Assessing the criteria}
 
From my perspective, current VAAs use a correct method to choose the policy issues at stake and the positions of the political parties within them. Taken as given that VAA developers are policy experts acting in good faith, they can provide expertise on the issues at stake and the positions of the parties within them \cite{Garzia2014}. Experts are better positioned than users to decide the policy issues and the positions of the parties because they have more knowledge of the political realm. Therefore, I believe that most current VAAs are informative because they inform the user of the policy issues, the positions of the political parties within them, and offer an agreement based on these differences, which simplifies the voting decision. Furthermore, most current VAAs are transparent as they have open methods which can be roughly understood by users and experts \cite{gemenis2013estimating}. It is true that some VAAs do not publicise their distance matrix, but this is a failure which can easily be solved by putting them at the disposal of the public.
\\

However, current VAAs do not respect users' way of comparing and aggregating policy preferences. First, let us focus on the most controversial decision that VAA developers are taking: giving exactly the same weight to every question. From my standpoint, this is far from respectful to users' way of aggregating policy preferences in order to come up with a single vote. It relies on an imaginary world in which voters give the same importance to every policy issue when casting a vote. This assumption is empirically flawed in issue-voting as many studies have shown that voters consistently give more importance to some issues \cite{wlezien2005salience}. Beyond any empirical study, it is common sense to think that a VAA that weight all the issues equally will have problems in respecting users' own preferences. Certainly, it can be taken as given that voters care more about some specific policy issues when casting their votes, and this is not something that VAAs' vision on political competence should challenge. There is no way in which voter's political competence should be understood as the equalization of every policy issue to find which political party is closer to the user preferences ``if aggregated in such a way". Therefore, current VAAs, instead of declaring that they recommend political parties to the users according to their own preferences, should claim that ``given a world in which everyone cares exactly the same about a policy issue regarding euthanasia, one on taxes and another on immigration", VAAs can increase  political competence. This is not solved by giving users the opportunity to add more/less weight to a question, as the multiplication/division by two is still arbitrary and can only marginally improve the respect toward users' own preferences. Is there any specific reason to multiply/divide by two and not another number?
\\

A similar problem occurs with matrix distances. The method used to establish the same matrix for every question according to proximity or directional theory is criticisable. First, it assumes that these theories are the only sources of inspiration for the construction of the matrix. This is an important decision which should be clarified by VAA developers, as there is an ongoing discussion in political science on whether voters compare their positions on the policy issues with those of the political parties following any proximity or directional theory \cite{dinas2016dead}. Second, even assuming that these theories are the most appropriate in order to build the matrix, it is not really clear that the same matrix can be used for every policy issue. For example, \cite{kropko2018issue} found that each policy issue follows its own logic, as they potentially respond to different patterns of behaviour which are difficult to disentangle ex-ante. Beyond empirical research, it is quite imaginable that users may be driven differently in their disagreement about visceral policy issues (such as some  regarding social rights. e.g. homosexual rights) in which directional logic is more sound than in others regarding taxes, in which a proximity logic may be expected. Therefore, it is difficult to know ex-ante which theory of voting is better fitted to the users of the application. This can be seen in those studies which have tried to evaluate the distance matrix, such as those of Mendez [2012 and 2017]. Their main conclusion is that a hybrid matrix, not following any clear voting logic, fits better with users' policy preferences \cite{Mendez2017}. Once accepted that an ex-ante established hybrid matrix better fits users' way of comparing their policy preferences with those of political parties, the main question which remains unanswered is why other distance matrices have not been tested.
\\

Regarding the realism criterion, current VAAs do not prove to be realistic. VAA developers have only tried to improve accuracy and weighted mean rank between users' expected and recommended party without differentiating between issue and non- issue voters \cite{louwerse2014design}. This is a poor way of improving the realism of the application, as it does not consider all the other possible factors that can influence non-issue voters and does not differentiate between kinds of users. In the scarce studies in which issue-voters have been differentiated, accuracy and weighted mean rank of VAAs have been below expectations \cite{Mendez2017}. For example, after differentiating between issue and non-issue voters by their responses to the supporting questions, I found that the EU-Vox 2014 recommended to ``issue-voter" users their previously preferred party in a percentage only slightly superior to a matching purely randomly (approximately 25\% accuracy and 3 in mean rank, meaning that the preferred party appeared on average in the third position in the set of recommended parties). To illustrate the importance of this point, I hypothesize a dumb algorithm that recommends everyone the party most prevalent in the overall voting intentions, then the second one and so on, regardless of users and parties' answer to the questions. Such algorithm obtained similar outcomes regarding accuracy (28\%) and mean rank (3.44). This is not an exclusive problem of the EU-Vox 2014, as this methodology is representative of other VAAs. Regarding the overall matching with political parties, I emulated the recommendation process for the Spanish issue-voter users in the EU-Vox 2014 and found that some parties were strikingly overestimated or underestimated by the application. This can be seen in Figure \ref{fig:Matrix}.

\begin{figure}[h]
    \centering 
    \includegraphics[width=0.6\linewidth]{confVAA_barra.eps}
    \caption{Confusion matrix between recommended and preferred parties. Darker colours represent a higher percentage of coincidence while lighter colours mean lower. The squares forming the diagonal line correspond to the cases in which the recommended and the preferred party were the same. The values are normalized by columns so the values of each column sum up to 100.}
    \label{fig:Matrix}
\end{figure}

Figure \ref{fig:Matrix} reveals two problems of current VAAs. First, low accuracy is reflected in the fact that the squares forming the diagonal line are not always darker than other squares in the same column. This means that some parties are mainly being  recommended to users who intended to vote for another party. Second, the fact that the diagonal line is sharply heterogeneous means that parties are receiving different treatment by the application. For example, while most users receiving a recommendation to vote for the Partido Popular (PP) had declared that they would vote for that party, the opposite is true for their major competitor in 2014, Partido Socialista Obrero Español (PSOE), whose recommendations match users' voting intentions very oddly. This is problematic as the application should try to offer a realistic landscape of the political parties to all the users, and this can hardly be happening if the application significantly overvalues and undervalues some political parties without a sound justification. The remaining question is the following: Is there any possible justification for benefiting some parties over others in such a remarkable way? I believe that this is not the case, at least if we take as given that they are issue-voters and the knowledge on politics of VAA users is more or less evenly distributed between voters of different parties. Therefore, matching among users declaring different initial voting parties should not totally differ when a large and representative sample of voters of the party is taken, as was the case with PP and PSOE declared voters in the EU-Vox 2014. Some differences between the parties may be acceptable (e.g. a majority of users could mistakenly conceive the position of their preferred party on some policy issues and therefore lead to a misrepresentation of that party or there is a major concentration of parties in some policy issues), but a confusion matrix with such a heterogeneous diagonal line is problematic and suggests a consistent bias towards some political parties due to the VAA method. 
\\

To sum up, all the symptoms suggest lack of realism; accuracy and mean rank are close to random matching, and there is a misrepresentation of the political landscape clearly benefiting some parties. Even more worryingly, I have argued that current models do not respect users' way of aggregating and comparing policy issues, a serious failure that could at the same time be the very reason for the lack of realism. Therefore, we need to find out why, in spite of these critical problems in increasing political competence, VAA developers have decided to equally weight the questions, use a predetermined matrix distance, and not differentiate between issue and non-issue voters. More specifically, it is particularly difficult to find a reasonable justification for their weighting decision because there is no single theory of voting which suggests that a competent voter must give the same importance to all policy issues. A possible justification is that they did not find any other way to do it better. Every possible weighting decision set ex-ante will be liable to the same criticism made before. In that case, it seems logical to equally weight all the questions to give an ``appearance of neutrality" to the method. Insofar as other weighting is used, for example adding special weights to economic issues, the fact that experts are choosing the topics which must be important for voters while the former criticism has not been resolved can be criticised. Therefore, giving the same weight to the questions may be seen as preferable to any other ex-ante weighting decision, and following this argument, the problem is intrinsic to the ex-ante non-empirical logic employed by VAAs to weight the questions. 
\\

The remaining question is whether other methods that empirically establish the weights of the policy issues and the matrix distances can solve the current VAA problems and increase voters' political competence. One option is to find an empirical way to establish ex-ante the weight of the questions (i.e. to adapt the result of other surveys to establish the weights of the policy issues). I think that this is an interesting idea worth discussion by VAA developers, but the difficulties with current survey data are enormous, as there is no available information on the exact value that users give to the thirty policy issues used by VAAs. Because of these complications, I cannot test this option in this essay. My proposal follows a different logic that can be implemented with our current stage of knowledge on VAAs: a learning algorithm that adapts the weights of the questions and the distance functions to users' own way of comparing and aggregating policy issues. There are two reasons why I believe that a learning method is superior. First, VAA users suffer from a self-selection bias and they are not representative of other surveys' samples \cite{cedroni2010voting}. Therefore, in order to get a representative sample of VAA users to adapt the questions and the distance functions, I should use data from VAA surveys, which in their current state are totally insufficient to carry out such a complex analysis. Second, other non-learning methods would have problems if the users of the application are not as previously expected. For example, this can happen if some citizens who previously were not using VAAs start filling in the application because of an external factor. In that case, a learning method could be adapted to these new users, but a pre-established method could not.

\section{My proposal: Learning VAA}
\subsection{Main idea}

The starting point of my proposal is current VAAs, as I use their approach to calculate agreement scores between user and parties. The main differences are two: a) it tells users that VAAs are only able to make a recommendation based on the disagreement between users and political parties on policy issues and b) it uses a distance matrix function and a weight of policy issues coming from a learning algorithm designed to be adapted to users' way of comparing and aggregating policy issues. Regarding the first point, my proposed VAA informs users from the very first moment that the recommendation will solely be based on their disagreement with the political parties in the answered questionnaire. Moreover, it asks users how valuable they consider the recommendation provided insofar as they based their voting decision only on the policy positions of the political parties, and ask their voting intention given the very same condition.Thanks to that, I expect to better filter the factors beyond policy issues that influence voting decisions. Unfortunately, as this was not the case in the EU-Vox 2014 and I cannot retrospectively make these sorts of questions, I cannot test with my current data the results of this part of the proposal. As a second best option, I have distinguished between issue and non-issue voters due to the answers of the users to the supporting questions regarding issue-voting in the EU-Vox 2014 \cite{Mendez2017}.
\\

To learn how to adapt the weighting of the questions and the distance functions following users' answers and intention to vote, learning VAA uses an algorithm that gets the issue-voter users profiles along with their voting intentions and tries to adjust its parameters (distance matrices and weights) in order to produce an agreement score closer to the voting intentions. Therefore, each  of the $M$ users has a user profile, $\Vec{u_i}$, a voting intention, $c_i$, and $K$ parties to potentially vote for, each with its corresponding profile, $\Vec{p_k}$. The agreement score for question $j$ between user $i$ and party $k$ is computed with a distance matrix, as in the current model:
\begin{equation}
    q_{ikj} = \Vec{u_{ij}} \times D_j \times \Vec{p_{kj}}^T \: .
\end{equation}

In my model, instead of a single matrix there are $N$ distance matrices, one for each question. Therefore, my model does not assume that users compare all the policy issues following the same logic. Matrices are diagonally symmetrical in their parameters, as distances in the answers from users to parties should be the same as inverse. A symmetry in the secondary diagonal is also introduced, corresponding to the logical symmetry between agreement and disagreement; it is enough to reformulate the question into a negative version of it for flipping the axis. Distance matrix (D) for question $j$ can be written as
\begin{equation}
\left( \begin{array}{c c c c c c c}
       & CA & A & N & D & CD & NO\\
    CA & \boldsymbol{d_{11}} & d_{21} & d_{31} & d_{41} & d_{51} & d_{61} \\
    A & \boldsymbol{d_{21}} & \boldsymbol{d_{22}} & d_{32} & d_{42} & d_{41} & d_{62} \\
    N & \boldsymbol{d_{31}} & \boldsymbol{d_{32}} & \boldsymbol{d_{33}} & d_{32} & d_{31} & d_{63} \\
    D & \boldsymbol{d_{41}} & \boldsymbol{d_{42}} & d_{32} & d_{22} & d_{21} & d_{62} \\
    CD & \boldsymbol{d_{51}} & d_{41} & d_{31} & d_{21} & d_{11} & d_{61} \\
    NO & \boldsymbol{d_{61}} & \boldsymbol{d_{62}} & \boldsymbol{d_{63}} & d_{62} & d_{61} & \boldsymbol{d_{66}}
\end{array}
\right),
\end{equation}
with all unique parameters in bold. The aggregated scores of the $N$ questions are aggregated in the same way as current models:
\begin{equation}
    s_{ik} = \sum\limits_{j=1}^N w_j \: q_{ijk} = \Vec{w} \cdot \Vec{q_{ik}} \: ,
\end{equation}

In my model, weights will change as the model learns from users' answers and their voting intention (given that they are issue-voter users or are asked to vote as if they were). The goal of the learning part is to find which parameters --- which values for the distance matrices and weights --- lead to best party predictions (figure \ref{fig:nodos}).

\begin{figure}[h]
    \centering 
    \includegraphics[width=0.55 \linewidth, bb = 0 0 847 407]{nodos.jpeg}
    \caption{Transformation of a user profile and a party profile for getting the conjoined score $s_{ik}$. Learning VAA adapts weights (w) and distance matrices (D) depending on users' answer to the questions and their voting intention. Therefore, it uses different weights and distance instead of the same one.}
    \label{fig:nodos}
\end{figure}

How well the goal is met can be quantified by the \textit{log loss} function, a common performance measure for multi-class classification tasks. This function gives  the classification error for user $i$, $ce_i$, which will be the goal function that the algorithm needs to minimize with respect to the parameters. Finding the parameters that minimize the error can be achieved in the same way as any optimization problem: by computing the partial derivatives in the parameter space and finding the critical points (the ones whose partial derivatives are equal to zero). A method that performs a local search in the parameter space is \textit{gradient descent}, which relies on the information carried by the derivatives. The gradient of a function at a certain point shows the direction in the parameter space in which the error diminishes the fastest. By taking a step (changing the parameters) in that direction, the new state (parameter set) should have a lower error. By iterative steps, the algorithm would eventually reach a local minimum (Figure \ref{fig:gdescent}).

\begin{figure}[h]
    \centering 
    \includegraphics[width=0.5\linewidth, bb = 0 0 565 354]{gdescent.png}
    \caption{Gradient descent algorithm \cite[Ch. 4]{Geron2017}. By taking small steps in the direction of lowering errors, the optimal set of parameters, $\hat{\theta}$, can be found.}
    \label{fig:gdescent}
\end{figure}

Every step size is determined by the learning rate, $\mu$, ---chosen by the developer, many different techniques allow for an efficient selection \cite[84]{Goodfellow-et-al-2016}--- and the gradient of the function:
\begin{equation}
    w_{t+1} = w_t - \mu \sum_{i=1}^M \frac{\partial ce_i}{\partial w}
\end{equation}

Therefore, in my proposal a learning scheme would update the parameters as the users fill in the VAA, performing new iterations of the gradient descent algorithm as new user points are added. Moreover, my model gives users the opportunity to indicate whether a particular policy issue is more important for them. It differentiates users relying on which questions they declared to be more important and thus it trains different models relying on the users' profiles.

\subsection{Assessing the criteria}

First, my VAA is informative for the very same reasons that current VAAs are: it follows the same logic to inform on policy issues, the positions of the parties within them and offer a recommendation based on the agreements between users and parties on policy issues. Therefore, if it is accepted that current VAAs are informative it must be accepted that my VAA accomplishes the same criteria. 
\\

Second, my VAA is more respectful of users' way of comparing and aggregating policy preferences. Differing from current VAAs, users are the starting point to make the comparison and aggregation, with the objective of offering them an unobstructed view of the political landscape without overestimating or underestimating policy issues. It does this by only considering users who are ``issue-voters", and thus it filters the reasons for voting for a party not controlled by VAAs.  Instead of equally weighting all policy issues and using a predetermined matrix for all the questions, my VAA learns to adapt weights and distance functions to users' way of comparing and aggregating preferences. For example, my model can discover whether some policy issues regarding salient topics are more important in casting a vote. That was the case in the EU-Vox 2014, where it was found that the questions over the independence of Spanish Regions were the most explanatory of the voting decision. Further research can be conducted on these interesting points, which could shed light on the very reasons for voting for a party in different countries. Moreover, my model considers whether a user thinks that a question is more/less important, and it makes a recommendation based on previous users with similar important questions, weighting these questions accordingly to the voting intentions of this set of users. Thanks to that, it avoids multiplying/dividing randomly by a number. Furthermore, as every policy issue follows a difference distance matrix relying on users, my model distinguishes between the way of comparing different policy issues. We found that questions regarding migration policy follow a directional logic while others regarding economic issues are closer to proximity models. More interestingly, it has been found that there were policy issues close to the proximity, directional and hybrid matrix, while other policy issues were following either unexpected but sound logic or rather non-sense logic (figure \ref{fig:sample}). Further research should be focused on the deeper causes of these matrices, as they can contribute to the current debate regarding issue-voting and proximity and directional theory.

\begin{figure} [h]
    \centering 
    \includegraphics[width=1\linewidth, bb = 0 0 1200 250]{sample_distances.png}
    \caption{Five sample distance matrices produced by the learning model. The first three samples resemble the previously proposed distance matrices, while others may suggest new paradigms of issue-voting or rather be learning spurious rules from the data (suggesting that either the users did not understand the question or that the parties were wrongly positioned).}
    \label{fig:sample}
\end{figure}


Third, the learning VAA is more realistic. Regarding accuracy and weighted mean rank for issue voters, it has considerably better percentages. While the EU-Vox 2014 reached an accuracy for issue voters in Spain of 25\% and a mean rank of 3 following current methods, with my learning model it reaches an accuracy close to 40\%, a better F-score and a mean rank close to 2 (Table 1).
\\

\begin{table}[h]
    \centering
    \begin{tabular}{cccc}
    \hline
        	         & Accuracy & F-score   & Mean rank \\ 
        Current VAAs & 0.252    & 0.251     & 3.00 \\ 
        Learning VAAs	 & 0.395    & 0.355     & 2.04
    \end{tabular}
    \caption{Comparison of results between current VAAs and learning VAA.}
    \label{tab:results}
\end{table}


Moreover, the overall matching between users and political parties improves substantially, without having indubitable errors regarding the over and under representation of some parties. To check this, I have calculated the mean rank and the F-score for each political party, and found that they improved considerably. Moreover, we can see Figure \ref{fig:comparison} comparing the matching of current and learning VAAs for the EU-Vox 2014 Spanish users. 

\begin{figure}[h]
    \centering 
    \includegraphics[width=1\linewidth, bb = 0 0 1000 554]{Comparison.png}
    \caption{Confusion matrices of current and learning VAAs.}
    \label{fig:comparison}
\end{figure}

As can be seen, in my model, the diagonal line of squares is darker than the rest of the square of the column (meaning that every party was recommended in a greater percentage to those users declaring that they intended to vote for that party) and is more homogeneous (meaning that it has improved the over and under valuation of some political parties). In any case, these promising preliminary results could still be improved in new VAAs if the other changes are implemented. Therefore, it is necessary to wait for the results from the new data (EU-Vox 2019) in order to validate my model. For example, I cannot yet know whether users consider that the recommendation of my model respects their policy preferences more than previous models, as it is impossible to retrospectively measure that. 
\\

The main problem with my proposal is the lack of transparency. Even if all the methods used are open to the public and researchers, there will be problems regarding the opaqueness of the method. Users may find it difficult to understand the mechanism behind the recommendation. Even if the weights of the questions and the distance functions are displayed on a screen, there will be difficulties in understanding why some issues are given more importance than others, and why a complicated matrix distance without any straightforward meaning is used in a few policy issues. In these circumstances, the VAA goal of increasing political competence may be undermined because the agreement score is not easy to interpret. For researchers, my VAA has a shared problem with other sophisticated inductive methods: being able to interpret the outcome in a meaningful and reliable way is not always straightforward. This can be a problem with methods relying on sophisticated machine learning which can have similarities with black boxes. In them, the internal mechanism producing the output from the set of inputs is not known. In these cases, researchers may have difficulties providing a meaning to the output of the application, undermining any valuable outcome of the VAA.  
\\

To alleviate the problem of users lack of understanding, I propose open access to the weightings and the distance functions of each of the questions in understandable figures. First, the method must be explained in the simplest possible way, and total access to all the relevant information must be guaranteed. Second, users should have the opportunity to declare whether they  understand the method used to provide a recommendation and if they prefer to get a recommendation with a different method. Third, at the end of the questionnaire a user should have access to a figure displaying the weights of all the questions, such as figure 8. Fourth, users should be able to press any of the questions to see the distance matrix used, and which voting theory better fits that question. 

\begin{figure}[h]
    \centering 
    \includegraphics[width= 0.95 \linewidth]{weights20180817-150608.eps}
    \label{fig:weights}
    \caption{Weights of each policy issue}
\end{figure}



\section{Conclusion}

In this essay, I have argued that current VAAs are not adequate to increase voters' political competence. After establishing four criteria to evaluate whether a VAA is likely to increase political competence, I have argued and empirically probed that current VAAs fail fundamentally in two of them: respect for users' way of comparing and aggregating policy issues and realism. After that, I have proposed a learning VAA that improves these two criteria while maintaining informativeness. However, I have accepted that there may be some problems regarding the transparency of the method, especially because of the complexity in understanding the recommendation that some users may experience. Therefore, my research tackles the problem of previous VAAs by proposing a new method based on machine learning techniques which can bring us closer to the ultimate goal of increasing voters' political competence, but results are still provisional and should be subjected to further scrutiny in future VAAs. This essay may open a new field of research on VAAs which may potentially increase their possibilities, even opening a new line of research on issue-voting and the validity of proximity and directional theory.

\pagebreak


\bibliographystyle{apalike}
\bibliography{bib}
\end{document}
